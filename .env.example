# Rename this file to `.env` and set your own variables and credentials.

MODEL_PATH="models/[your-model-name].gguf"  # The path of your model.
CTX_LENGTH=32768                            # The context length of your model.

MODEL_TEMP=1.0                              # The temperature for your model.
MODEL_BASE_URL=<SET-YOUR-BASE-URL>
MODEL_NAME=<SET-YOUR-MODEL-NAME>
MODEL_API_KEY=<SET-YOUR-API-KEY>

INFERENCE_TYPE="api"                        # Set this to either "api" for cloud LLM or "local" for llama-cpp inference.

# Below values can be configured as per preference.
MONGO_USER="admin"
MONGO_PASS="password123"
MONGO_MSG_DB="ichat"
MONGODB_URI="mongodb://admin:password123@mongodb:27017/"  # Enter your MongoDB URI with username and password set in docker compose.


LANGFUSE_PUBLIC_KEY=<Enter-Langfuse-Public-Key>
LANGFUSE_SECRET_KEY=<Enter-Langfuse-Secret-Key>

EMBEDDING_URL=http://tei-embedder:8080
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

QDRANT_URL="http://qdrant:6333"
QDRANT_COLLECTION="memories"

GRAPHDB_URL="bolt://localhost:7687"
GRAPHDB_USER="neo4j"
GRAPHDB_PASS="neo4j_password"
